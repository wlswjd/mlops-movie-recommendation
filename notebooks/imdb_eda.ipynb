{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d2d8be0-9623-43b5-af82-f201edc36565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
      "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
      "2  If only to avoid making this type of film in t...      0\n",
      "3  This film was probably inspired by Godard's Ma...      0\n",
      "4  Oh, brother...after hearing about this ridicul...      0\n",
      "label\n",
      "0    12500\n",
      "1    12500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 🤗 HuggingFace Datasets, Pandas 불러오기\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# IMDB 데이터셋 로드\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# 학습/테스트 셋을 Pandas로 변환\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "test_df = dataset[\"test\"].to_pandas()\n",
    "\n",
    "# 기본 구조 확인\n",
    "print(train_df.head())\n",
    "print(train_df[\"label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf81c481-e850-4284-af4e-883d850087c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/relaxman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 벡터화 완료! 학습 샘플 수: 20000, 검증 샘플 수: 5000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 정제 함수 정의\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # 소문자화\n",
    "    text = re.sub(r\"<br />\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)  # 알파벳만 남기기\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # 연속된 공백 제거\n",
    "    return text.strip()\n",
    "\n",
    "# 전처리 적용\n",
    "train_df[\"clean_text\"] = train_df[\"text\"].apply(clean_text)\n",
    "\n",
    "# 불용어 제거 + TF-IDF 벡터화\n",
    "stop_words = stopwords.words('english')\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=stop_words)\n",
    "\n",
    "X = vectorizer.fit_transform(train_df[\"clean_text\"])\n",
    "y = train_df[\"label\"]\n",
    "\n",
    "# 학습/검증 나누기\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"TF-IDF 벡터화 완료! 학습 샘플 수: {X_train.shape[0]}, 검증 샘플 수: {X_val.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed604ad3-c891-46fc-8521-45feed44e706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/05/28 14:59:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 학습 완료! Accuracy: 0.8844\n",
      "🏃 View run classy-turtle-869 at: http://localhost:5050/#/experiments/2/runs/fdc088af57e8446a9592e32a647ba336\n",
      "🧪 View experiment at: http://localhost:5050/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://localhost:9000\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minioadmin\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin\"\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5050\")\n",
    "mlflow.set_experiment(\"imdb-logreg-classification\")\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model\", \"LogisticRegression\")\n",
    "    mlflow.log_param(\"max_iter\", 1000)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    print(f\"✅ 모델 학습 완료! Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf4769a-0b75-4c76-aada-4c7bef0b26da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
